{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright **`(c)`** 2023 Giovanni Squillero `<giovanni.squillero@polito.it>`  \n",
    "[`https://github.com/squillero/computational-intelligence`](https://github.com/squillero/computational-intelligence)  \n",
    "Free for personal or classroom use; see [`LICENSE.md`](https://github.com/squillero/computational-intelligence/blob/master/LICENSE.md) for details.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB10\n",
    "\n",
    "Use reinforcement learning to devise a tic-tac-toe player.\n",
    "\n",
    "### Deadlines:\n",
    "\n",
    "* Submission: [Dies Natalis Solis Invicti](https://en.wikipedia.org/wiki/Sol_Invictus)\n",
    "* Reviews: [Befana](https://en.wikipedia.org/wiki/Befana)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations, chain\n",
    "from collections import namedtuple, defaultdict\n",
    "from random import choice\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "from typing import Literal\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "State = namedtuple('State', ['x', 'o'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TicTacToe:\n",
    "    def __init__(self):\n",
    "        self.board = np.zeros((3, 3))\n",
    "        self.state = State(set(), set())\n",
    "        self.magic = np.array([[2, 7, 6], [9, 5, 1], [4, 3, 8]])\n",
    "        self.marks = {-1: 'O', 0: '.', 1: 'X'}\n",
    "        self.winner = None\n",
    "        self.game_over = False\n",
    "    \n",
    "    def print_board(self):\n",
    "        \"\"\"\n",
    "        Print intuitive table\n",
    "        \"\"\"\n",
    "        board = np.chararray(self.board.shape, itemsize=1, unicode=True)\n",
    "        for i in range(board.shape[0]):\n",
    "            for j in range(board.shape[1]):\n",
    "                board[(i, j)] = self.marks[self.board[(i, j)]]\n",
    "        print(board)\n",
    "\n",
    "    def get_state(self):\n",
    "        \"\"\" \n",
    "        get hashable state\n",
    "        \"\"\"\n",
    "        return State(frozenset(self.state.x), frozenset(self.state.o))\n",
    "    \n",
    "\n",
    "    def win(self, elements):\n",
    "        \"\"\"\n",
    "        Checks if elements is winning\n",
    "        \"\"\"\n",
    "        return any(sum(c) == 15 for c in combinations(self.magic[elements], 3))\n",
    "    \n",
    "    \n",
    "    def check_winner(self):\n",
    "        \"\"\"\n",
    "        Check if there's a winner\n",
    "        \"\"\"\n",
    "\n",
    "        p1 = self.board == 1\n",
    "        p2 = self.board == -1\n",
    "\n",
    "        if self.win(p1):\n",
    "            self.winner = 'X'\n",
    "            self.game_over = True\n",
    "            return 1\n",
    "        elif self.win(p2):\n",
    "            self.winner = 'O'\n",
    "            self.game_over = True\n",
    "            return -1\n",
    "        if 0 not in self.board:\n",
    "            self.game_over = True\n",
    "            return 0\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "\n",
    "    def is_valid_move(self, action):\n",
    "        return self.board[action] == '.'\n",
    "    \n",
    "\n",
    "    def make_move(self, action, id):\n",
    "        self.board[action] = id\n",
    "        self.check_winner()\n",
    "\n",
    "        if id == 1:\n",
    "            self.state.x.add(action)\n",
    "        elif id == -1:\n",
    "            self.state.o.add(action)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-Learning Player Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QLPlayer:\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        epsilon = float(.7),\n",
    "        alpha = float(.09),\n",
    "        gamma = float(.9),\n",
    "    ):\n",
    "        self.epsilon = epsilon\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.q_table = {}\n",
    "    \n",
    "    def get_q_val(self, state, action):\n",
    "        \"\"\"\n",
    "        Get a value from the quality table, given a state-action pair\n",
    "        \"\"\"\n",
    "        return self.q_table.get((state, action), 0.0)\n",
    "    \n",
    "    def update_q_table(self, state, action, reward, next_state):\n",
    "        \"\"\"\n",
    "        Update values of the quality table\n",
    "        \"\"\"        \n",
    "        if state not in self.q_table:\n",
    "            self.q_table[state] = np.zeros((9))\n",
    "        if next_state not in self.q_table:\n",
    "            self.q_table[next_state] = np.zeros((9))\n",
    "\n",
    "        # math\n",
    "        q_val = reward + self.gamma * np.max(self.q_table[next_state])\n",
    "        self.q_table[state][action] = (1 - self.alpha) * self.get_q_val(state, action) + self.alpha * q_val\n",
    "\n",
    "\n",
    "    def make_move(self, state, available_moves, training: bool):\n",
    "        \"\"\"\n",
    "        Make a move, choosing between exploration and exploitation based on epsilon\n",
    "        \"\"\"\n",
    "        # exploration\n",
    "        if np.random.rand() < self.epsilon and not training:\n",
    "            return np.random.choice(available_moves)\n",
    "        \n",
    "        # exploitation\n",
    "        else:\n",
    "            q_val = [self.get_q_val(state, action) for action in available_moves]\n",
    "            return available_moves[np.argmax(q_val)]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ql_game(game: TicTacToe, agent):\n",
    "    available_moves = [i for i in range(9)]\n",
    "    id = 1\n",
    "    final_reward = 0\n",
    "    state = game.get_state()\n",
    "\n",
    "    while not game.game_over:\n",
    "        \n",
    "        action = agent.make_move(state, available_moves, True)\n",
    "        available_moves.remove(action)\n",
    "        game.make_move((action // 3, action % 3), id)\n",
    "\n",
    "        \n",
    "        next_state = game.get_state()\n",
    "        reward = 0\n",
    "\n",
    "        if game.game_over:\n",
    "            if game.winner == 1:\n",
    "                reward = 1\n",
    "            elif game.winner == -1:\n",
    "                reward = -1\n",
    "            else:\n",
    "                reward = 0\n",
    "        \n",
    "        agent.update_q_table(state, action, reward, next_state)\n",
    "        state = next_state\n",
    "        final_reward += reward\n",
    "        id = -id\n",
    "    \n",
    "    return final_reward\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9890474b6b33482285ae2436390df5c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "agent = QLPlayer()\n",
    "final_reward = 0\n",
    "\n",
    "for steps in tqdm(range(50_000)):\n",
    "    game = TicTacToe()\n",
    "    final_reward += ql_game(game, agent)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test against Random Player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game Over. Winner: O\n",
      "[['X' '.' 'O']\n",
      " ['O' 'O' 'X']\n",
      " ['O' 'X' 'X']]\n",
      "\n",
      "   *****   \n",
      "\n",
      "Game Over. Winner: X\n",
      "[['X' 'X' 'X']\n",
      " ['O' '.' 'O']\n",
      " ['X' 'O' '.']]\n",
      "\n",
      "   *****   \n",
      "\n",
      "Game Over. Winner: X\n",
      "[['X' 'O' 'O']\n",
      " ['X' 'X' '.']\n",
      " ['O' '.' 'X']]\n",
      "\n",
      "   *****   \n",
      "\n",
      "Game Over. Winner: None\n",
      "[['X' 'O' 'X']\n",
      " ['X' 'X' 'O']\n",
      " ['O' 'X' 'O']]\n",
      "\n",
      "   *****   \n",
      "\n",
      "Game Over. Winner: X\n",
      "[['.' 'O' 'X']\n",
      " ['.' 'O' 'X']\n",
      " ['O' 'X' 'X']]\n",
      "\n",
      "   *****   \n",
      "\n",
      "Game Over. Winner: O\n",
      "[['X' 'X' 'O']\n",
      " ['O' 'O' 'O']\n",
      " ['.' 'X' 'X']]\n",
      "\n",
      "   *****   \n",
      "\n",
      "Game Over. Winner: X\n",
      "[['X' 'X' 'X']\n",
      " ['X' 'O' 'O']\n",
      " ['.' 'O' '.']]\n",
      "\n",
      "   *****   \n",
      "\n",
      "Total wins: 4/10\n",
      "Total losses: 2/10\n"
     ]
    }
   ],
   "source": [
    "\n",
    "total_wins = 0\n",
    "total_losses = 0\n",
    "\n",
    "for _ in range(7):\n",
    "    game = TicTacToe()\n",
    "    state = game.get_state()\n",
    "    available_moves = [i for i in range(9)]\n",
    "    id = 1\n",
    "\n",
    "    while not game.game_over:\n",
    "        # player 1, q-learner\n",
    "        if id == 1:\n",
    "            action = agent.make_move(state, available_moves, False)\n",
    "            available_moves.remove(action)\n",
    "            game.make_move((action // 3, action % 3), id)\n",
    "            state = game.get_state()\n",
    "\n",
    "\n",
    "        # player 2: random player\n",
    "        elif id == -1:\n",
    "            action = choice(list(available_moves))\n",
    "            available_moves.remove(action)\n",
    "            game.make_move((action // 3, action % 3), id)\n",
    "            state = game.get_state()\n",
    "        \n",
    "        id = -id\n",
    "\n",
    "    print(f\"Game Over. Winner: {game.winner}\")\n",
    "    if game.winner == 'X':\n",
    "        total_wins += 1\n",
    "    elif game.winner == 'O':\n",
    "        total_losses += 1\n",
    "    game.print_board()\n",
    "    print(\"\\n   *****   \\n\")\n",
    "\n",
    "print(f\"Total wins: {total_wins}/10\")\n",
    "print(f\"Total losses: {total_losses}/10\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ci-P-7LqQ3C-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
